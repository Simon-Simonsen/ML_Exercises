{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a168987-8d24-46f9-893a-f99613c96f93",
   "metadata": {},
   "source": [
    "<b>Machine Learning Exercise session: 25th September 2025</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5587de67-4b16-466d-b938-5cf0be968926",
   "metadata": {},
   "source": [
    "# <b>Working with: LDA and QDA in several dimensions</b>\n",
    "\n",
    "Welcome to this week's exercise session. In today’s notebook, we will explore **Linear Discriminant Analysis (LDA)** and **Quadratic Discriminant Analysis (QDA)** in the context of multidimensional data.\n",
    "We will build on the generative models studied last week and see how they extend to higher-dimensional settings.\n",
    "\n",
    "The exercises are structured in 3 sections (Theory-t, Application-a, Exploration-e). Here is a table to guide you through this sheet:\n",
    "\n",
    "|Type|Ex|\n",
    "|----|--|\n",
    "|First do|e1, t3, e2|\n",
    "|Then do|a1, a2, t2|\n",
    "|End with|t1, a3|\n",
    "\n",
    "Remember \n",
    "- It is good practice to use the Machine Learning python environment you made in week 1. *Ensure that you are working within the virtual environment (venv) with **conda activate ml**. where **ml** is the name of the venv, and/or selecting it on VSCode/Jupyter*\n",
    "- Solving these exercises is supposed to take much longer than 90 minutes. Work on them before going to class.\n",
    "- Learning Machine Learning is challenging. Take your time, make some errors, and read the documentation if needed. <b>We are happy to help if you are stuck.</b>\n",
    "- **None of the exercises are mandatory, do your best to solve them! Every weekend solutions will be published!**\n",
    "- **Do not hesitate in reaching out to the TAs for any issue you might encounter while solving them**\n",
    "- *Remember to provide a Feedback on this Exercise sheet on the LearnIT page of the course so we can make an even better exercise session!*\n",
    "\n",
    "Have fun! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6629a7bc-7f16-4808-a4eb-fbba3570d85e",
   "metadata": {},
   "source": [
    "# <b>Exploring theoretical background</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1977fc",
   "metadata": {},
   "source": [
    "## Exercise t1\n",
    "\n",
    "1. In Linear Discriminant Analysis (LDA), the discriminant function for class \\(k\\) is  \n",
    "\n",
    "$$\n",
    "g_k(x) = 2\\log \\pi_k - (x - \\mu_k)^T \\Sigma^{-1}(x - \\mu_k),\n",
    "$$  \n",
    "\n",
    "where $\\pi_k$ is the prior, $\\mu_k$ the class mean, and $\\Sigma$ the (shared) covariance matrix.  \n",
    "\n",
    "A. What happens to the discriminant $g_k(x)$ when $\\pi_k$ increases?\n",
    "\n",
    "B. Show that the decision boundary between two classes is linear when covariances are assumed equal.  \n",
    "\n",
    "2. How does the boundary change when the covariances between classes differ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "304e7256",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your solution here..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6dca01",
   "metadata": {},
   "source": [
    "## Exercise t2 \n",
    "\n",
    "Below you see three examples of contour curves for a specific value of the three discriminant functions in a three-class classification with LDA,\n",
    "\n",
    "![contour plots of discriminant functions](images/img1.png)\n",
    "\n",
    "For each example, sketch the decision boundaries and decision regions for the LDA classifier as follows:\n",
    "\n",
    "a) First sketch the decision boundary between each pair of classes.\n",
    "\n",
    "b) Then decide the winning color in each of the six resulting regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d762e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f07bba4",
   "metadata": {},
   "source": [
    "## Exercise t3\n",
    "\n",
    "What are the main differences between LDA, QDA, Naive Bayes, and Logistic Regression in terms of assumptions, decision boundaries, and flexibility?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "783cc920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d46ab69-03cf-40ad-856d-faa1291c915a",
   "metadata": {},
   "source": [
    "# <b>Applying what you learned</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b92b36a",
   "metadata": {},
   "source": [
    "In this part of the exercises, we will apply Linear Discriminant Analysis (LDA) and Quadratic Discriminant Analysis (QDA) to the wine dataset, which we previously used in the KNN exercise session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcde8262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of obervations:  177\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class  Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  \\\n",
       "0      1    13.20        1.78  2.14               11.2        100   \n",
       "1      1    13.16        2.36  2.67               18.6        101   \n",
       "\n",
       "   Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
       "0           2.65        2.76                  0.26             1.28   \n",
       "1           2.80        3.24                  0.30             2.81   \n",
       "\n",
       "   Color intensity   Hue  OD280/OD315 of diluted wines  Proline  \n",
       "0             4.38  1.05                          3.40     1050  \n",
       "1             5.68  1.03                          3.17     1185  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('Wine.csv')\n",
    "\n",
    "col_names = [\n",
    "    \"Class\",\n",
    "    \"Alcohol\",\n",
    "    \"Malic acid\",\n",
    "    \"Ash\",\n",
    "    \"Alcalinity of ash\",\n",
    "    \"Magnesium\",\n",
    "    \"Total phenols\",\n",
    "    \"Flavanoids\",\n",
    "    \"Nonflavanoid phenols\",\n",
    "    \"Proanthocyanins\",\n",
    "    \"Color intensity\",\n",
    "    \"Hue\",\n",
    "    \"OD280/OD315 of diluted wines\",\n",
    "    \"Proline\"\n",
    "]\n",
    "\n",
    "data.columns = col_names\n",
    "print('Number of obervations: ', len(data))\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337286c2",
   "metadata": {},
   "source": [
    "### Documentation\n",
    "\n",
    "- numpy : https://numpy.org/doc/stable/index\n",
    "- pandas : https://pandas.pydata.org/pandas-docs/stable/\n",
    "- matplotlib.pyplot : https://matplotlib.org/stable/tutorials/pyplot.html\n",
    "- scipy.stats : https://docs.scipy.org/doc/scipy/tutorial/stats.html\n",
    "- random: https://docs.python.org/3/library/random.html\n",
    "\n",
    "\n",
    "Sklearn:\n",
    "\n",
    "- generative models: https://scikit-learn.org/stable/api/sklearn.discriminant_analysis.html\n",
    "- knn: https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "- model_selection : https://sklearn.org/stable/api/sklearn.model_selection.html\n",
    "- metrics : https://scikit-learn.org/stable/api/sklearn.metrics.html\n",
    "- preprocessing: https://scikit-learn.org/stable/modules/preprocessing.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1a1348",
   "metadata": {},
   "source": [
    "### Exercise a1\n",
    "\n",
    "We will start working again with the first two features: Alcohol and Malic acid. Do a scatter plot of the data.\n",
    "\n",
    "1) Train an LDA classifier, and visualise the decision regions on a scatterplot.\n",
    "\n",
    "2) Compute the estimated posterior distribution of classes for a new observation ($x_1$, $x_2$) = (13, 2.5). Compare it with the estimated by the KNN-5 from the previous exercise session. \n",
    "\n",
    "3) Split the data into train and test, and report the final performance of the LDA model. Compare with KNN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e57a393e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf72bd5",
   "metadata": {},
   "source": [
    "## Exercise a2\n",
    "\n",
    "1) Do you think a QDA model would provide a better fit than the LDA model?\n",
    "\n",
    "2) Train a QDA classifier and visualize the decision regions on a scatterplot.\n",
    "\n",
    "3) Compute the model's accuracy and compare it with that of the LDA model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f515fb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1182504d",
   "metadata": {},
   "source": [
    "## Exercise a3\n",
    "\n",
    "1) Visualize the class distributions of both of the features. Examine whether the assumptions of LDA and QDA are satisfied or not. How does it affect the model's performance?\n",
    "\n",
    "2) Work with the features Alcohol and Total Phenols instead. Train again a LDA and QDA model, and plot the respective decision boundaries. Plot the distributions of the features on each class. How is the new model's performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffc3ad5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a635e31-0f16-427b-8c0b-6d069a4f4eba",
   "metadata": {},
   "source": [
    "# <b>Exploring what you learned</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6483cc",
   "metadata": {},
   "source": [
    "## Exercise e1\n",
    "\n",
    "1) Simulate a dataset with three Gaussian classes:\n",
    "    - First, use equal class priors (⅓, ⅓, ⅓).\n",
    "    - Then, use unequal class priors (0.7, 0.2, 0.1).\n",
    "\n",
    "2) Visualize the decision boundaries in both cases. Reflect on how changing the priors influences the position and shape of the decision boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c0272974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8ac9a8",
   "metadata": {},
   "source": [
    "## Exercise e2\n",
    "\n",
    "Simulate three two-dimensional Gaussian cases, each of them having three different classes distributed as follows:\n",
    "\n",
    "Case 1:\n",
    "$$\n",
    "Class_1 \\sim \\mathcal{N}\\Bigg(\\begin{bmatrix}-2 \\\\ 0\\end{bmatrix}, \n",
    "\\begin{bmatrix}1 & 0 \\\\ 0 & 1\\end{bmatrix}\\Bigg), \\quad\n",
    "Class_2 \\sim \\mathcal{N}\\Bigg(\\begin{bmatrix}0 \\\\ 3\\end{bmatrix}, \n",
    "\\begin{bmatrix}1 & 0 \\\\ 0 & 1\\end{bmatrix}\\Bigg), \\quad\n",
    "Class_3 \\sim \\mathcal{N}\\Bigg(\\begin{bmatrix}2 \\\\ -2\\end{bmatrix}, \n",
    "\\begin{bmatrix}1 & 0 \\\\ 0 & 1\\end{bmatrix}\\Bigg)\n",
    "$$\n",
    "\n",
    "Case 2:\n",
    "$$\n",
    "Class_1 \\sim \\mathcal{N}\\Bigg(\\begin{bmatrix}-2 \\\\ 0\\end{bmatrix}, \n",
    "\\begin{bmatrix}1.5 & 0 \\\\ 0 & 1.5\\end{bmatrix}\\Bigg), \\quad\n",
    "Class_2 \\sim \\mathcal{N}\\Bigg(\\begin{bmatrix}0 \\\\ 3\\end{bmatrix}, \n",
    "\\begin{bmatrix}0.5 & 0 \\\\ 0 & 0.5\\end{bmatrix}\\Bigg), \\quad\n",
    "Class_3 \\sim \\mathcal{N}\\Bigg(\\begin{bmatrix}2 \\\\ -2\\end{bmatrix}, \n",
    "\\begin{bmatrix}2.0 & 0 \\\\ 0 & 0.8\\end{bmatrix}\\Bigg)\n",
    "$$\n",
    "\n",
    "Case 3:\n",
    "$$\n",
    "Class_1 \\sim \\mathcal{N}\\Bigg(\\begin{bmatrix}-2 \\\\ 0\\end{bmatrix}, \n",
    "\\begin{bmatrix}1.5 & 0.98 \\\\ 0.98 & 1.0\\end{bmatrix}\\Bigg), \\quad\n",
    "Class_2 \\sim \\mathcal{N}\\Bigg(\\begin{bmatrix}0 \\\\ 3\\end{bmatrix}, \n",
    "\\begin{bmatrix}0.5 & -0.48 \\\\ -0.48 & 0.8\\end{bmatrix}\\Bigg), \\quad\n",
    "Class_3 \\sim \\mathcal{N}\\Bigg(\\begin{bmatrix}2 \\\\ -2\\end{bmatrix}, \n",
    "\\begin{bmatrix}1.2 & 1.14 \\\\ 1.14 & 1.5\\end{bmatrix}\\Bigg)\n",
    "$$\n",
    "\n",
    "1) Generate the data and inspect the scatterplot. Based on the distribution, which model do you expect to perform best in each case: LDA, QDA, Naive Bayes, or Logistic Regression?\n",
    "\n",
    "2) Train the four models mentioned above and plot their decision boundaries.\n",
    "\n",
    "3) Compute the test misclassification rates for each case and compare them. Do the results match your expectations?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e35c159e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
